{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import wget\n",
    "import cv2\n",
    "import urllib.request\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "\n",
    "#  Set headers to not get 403: Forbidden\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [(\"User-Agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:79.0) Gecko/20100101 Firefox/79.0\"), (\"Cache-Control\", \"no-store\")]\n",
    "urllib.request.install_opener(opener)\n",
    "image_url = \"https://thispersondoesnotexist.com/image\"  # 1024x1024\n",
    "\n",
    "\n",
    "\n",
    "#  Get n faces to download\n",
    "facecount = len([file for file in Path(\"./Data/High res\").iterdir()])\n",
    "\n",
    "command = input(\"'add' or 'del' ?  \")\n",
    "if command == \"add\":\n",
    "    try:\n",
    "        extrafaces = int(input(f\"Currently {facecount} faces available in './Data/High res'. How many more faces to download?  \"))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    i = facecount + 1\n",
    "\n",
    "    #  Download requested n faces\n",
    "    while i <= facecount + extrafaces:\n",
    "        filename = \"./Data/High res/face_{:0>5}.jpeg\".format(i)\n",
    "        image_filename = wget.download(image_url, filename)\n",
    "        sleep(1)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    t, t, hi_files = next(os.walk(Path(\"./Data/High res\")))\n",
    "    t, t, lo_files = next(os.walk(Path(\"./Data/Low res\")))\n",
    "\n",
    "    for img in hi_files:\n",
    "        if img not in lo_files:\n",
    "            cv2.imwrite(f\"./Data/Low res/{img}\", cv2.resize(cv2.resize(cv2.imread(f\"./Data/High res/{img}\", cv2.IMREAD_COLOR), (100, 100)), (1024, 1024)))\n",
    "elif command == \"del\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import urllib\n",
    "import platform\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# checkpoint callback\n",
    "checkpoint_path = f\"./ML/Checkpoints\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(checkpoint_path, f\"cp.ckpt\"), verbose=1, save_weights_only=True, save_freq=5) # -{epoch:02d}\n",
    "\n",
    "l2_alpha = 10e-10  # L2 regression\n",
    "\n",
    "# conv == size of convolution window in px\n",
    "def define_model(conv=250):\n",
    "    input_img = tf.keras.layers.Input(shape=(1024, 1024, 3))\n",
    "\n",
    "    l1 = tf.keras.layers.Conv2D(256, conv, padding=\"same\", kernel_initializer=\"he_uniform\", activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_alpha))(input_img)\n",
    "    l2 = tf.keras.layers.Conv2D(256, conv, padding=\"same\", kernel_initializer=\"he_uniform\", activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_alpha))(l1)\n",
    "    l3 = tf.keras.layers.MaxPool2D(padding=\"same\")(l2)\n",
    "\n",
    "    l4 = tf.keras.layers.Conv2D(512, conv, padding=\"same\", kernel_initializer=\"he_uniform\", activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_alpha))(l3)\n",
    "    l5 = tf.keras.layers.Conv2D(512, conv, padding=\"same\", kernel_initializer=\"he_uniform\", activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_alpha))(l4)\n",
    "    l6 = tf.keras.layers.MaxPool2D(padding=\"same\")(l5)\n",
    "\n",
    "    l7 = tf.keras.layers.Conv2D(1024, conv, padding=\"same\", kernel_initializer=\"he_uniform\", activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_alpha))(l6)\n",
    "\n",
    "    l8 = tf.keras.layers.UpSampling2D()(l7)\n",
    "    l9 = tf.keras.layers.Conv2D(512, conv, padding=\"same\", kernel_initializer=\"he_uniform\", activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_alpha))(l8)\n",
    "    l10 = tf.keras.layers.Conv2D(512, conv, padding=\"same\", kernel_initializer=\"he_uniform\", activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_alpha))(l9)\n",
    "\n",
    "    l11 = tf.keras.layers.add([l10, l5])\n",
    "\n",
    "    l12 = tf.keras.layers.UpSampling2D()(l11)\n",
    "    l13 = tf.keras.layers.Conv2D(256, conv, padding=\"same\", kernel_initializer=\"he_uniform\", activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_alpha))(l12)\n",
    "    l14 = tf.keras.layers.Conv2D(256, conv, padding=\"same\", kernel_initializer=\"he_uniform\", activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_alpha))(l13)\n",
    "\n",
    "    l15 = tf.keras.layers.add([l14, l2])\n",
    "\n",
    "    decoded_image = tf.keras.laeyrs.Conv2D(3, conv, padding=\"same\", kernel_initializer=\"he_uniform\", activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_alpha),)(l15)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=(input_img), outputs=decoded_image)\n",
    "\n",
    "\n",
    "model = define_model()\n",
    "model.save_weights(os.path.join(checkpoint_path, \"cp-00.ckpt\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "\n",
    "lo_res_images = []\n",
    "hi_res_images = []\n",
    "\n",
    "t, t, hi_files = next(os.walk(\"./Data/High res\"))\n",
    "t, t, lo_files = next(os.walk(\"./Data/Low res\"))\n",
    "\n",
    "for img in hi_files:\n",
    "    hi_res_images.append(cv2.imread(f\"./Data/High res/{img}\", cv2.IMREAD_UNCHANGED))\n",
    "    \n",
    "for img in lo_files:\n",
    "    lo_res_images.append(cv2.imread(f\"./Data/Low res/{img}\", cv2.IMREAD_UNCHANGED))\n",
    "\n",
    "print(len(lo_res_images))\n",
    "print(len(hi_res_images))\n",
    "\n",
    "\n",
    "# lo_res_images = np.array(lo_res_images, dtype=object)\n",
    "# hi_res_images = np.array(hi_res_images, dtype=object)\n",
    "\n",
    "# print(lo_res_images.shape)\n",
    "# print(hi_res_images.shape)\n",
    "\n",
    "model.fit(np.asarray(lo_res_images[:5]), np.asarray(hi_res_images[:5]), epochs=1, batch_size=32, shuffle=True, validation_split=0.15)\n",
    "# model.fit(lo_res_images, hi_res_images, epochs=5, batch_size=32, shuffle=True, validation_split=0.15, callbacks=[cp_callback])\n",
    "\n",
    "model.save(\"my_model\")\n",
    "\n",
    "\n",
    "sr1 = np.clip(model.predict(lo_res_images), 0.0, 1.0)\n",
    "# sr1 = cv2.cvtColor(sr1, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "plt.figure(figsize=(256, 256))\n",
    "\n",
    "plt.subplot(10, 10, 1)\n",
    "plt.imshow(lo_res_images[image_index])\n",
    "\n",
    "plt.subplot(10, 10, 2)\n",
    "plt.imshow(hi_res_images[image_index])\n",
    "\n",
    "plt.subplot(10, 10, 3)\n",
    "plt.imshow(sr1[image_index])\n",
    "\n",
    "plt.savefig(\"./\")"
   ]
  }
 ]
}